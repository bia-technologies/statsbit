Партицирование нужно в первую очередь для быстрого удаления старых данных.
Таблицы могут быть довольно большими, до 32ТБ.
И партиции делать маленькими особого смысла нет. Наверное, одни должны хранить месяц или квартал.

Для поиска по интервалам подходит 2 индекса: GIST и BRIN.
Оба неточные. Первый на порядок быстрее?
Второй очень маленький - мегабайт против сотен мегабайт у gist.
Наши данные подходят под brin индекс и мы много экономим на диске.
Одна проблема, планировщик почему-то не использует brin индекс,
он неправильно(?) расчитывает стоимость, наверняка можно что-то подкрутить.



1. нормализация
табличка с name, табличка с scope, внешние ключи.

Для запроса web-transactions нужны данные за 30 интервалов.
И эти переданные интервалы джоинятся к метрикам.
Потом джоинятся  скоупы и имена.
Пробелма в том, что планировщик строит медленный план.
И приходится использовать WITH, чтобы он материализовал выборки
метрик по суммарному интервалу, имен и скоупов.

При этом можно использовать ltree. что удобно для точных выборок.

2. денормализация
имена и скоупы хранятся вместе с метриками
растет размер таблицы, т.к. там очень много дублей

3. json, `join lateral jsonb_to_recordset(jsonb_field)`, zson для сжатия

```
select interval, metrics.*
from "metric-data"
join lateral jsonb_to_recordset(metrics)
  as metrics(name varchar(255),
             scope varchar(255),
             "call-count" integer,
             "total-call-time" float8,
             "total-exclusive-time" float8) on true
```



по поводу brin:
https://www.facebook.com/groups/postgresql/permalink/962164960646918/

когда будет колонка агентов, то имеет смысл сделать и по ней brin индекс, только на страницу,
а индекск по интервалу должен захватывать больше страниц в диапазоне.
